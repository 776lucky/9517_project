{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_datasets\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ==== è¶…å‚æ•° ====\u001b[39;00m\n\u001b[32m      7\u001b[39m IMG_SIZE = (\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from preprocessing import get_datasets\n",
    "\n",
    "# ==== è¶…å‚æ•° ====\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 5\n",
    "POS_WEIGHT = 5.0\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== åŠ è½½æ•°æ®é›† ====\n",
    "train_dataset, test_dataset = get_datasets(\"USA_segmentation\", IMG_SIZE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ==== å®šä¹‰ U-Net ====\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1):\n",
    "        super().__init__()\n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(0.1)\n",
    "            )\n",
    "\n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.bottleneck = conv_block(512, 512)\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 512, 2, stride=2)\n",
    "        self.dec4 = conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "        self.final = nn.Conv2d(64, out_channels, 1)\n",
    "        nn.init.constant_(self.final.bias, -2.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        d4 = self.dec4(torch.cat([self.upconv4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.upconv3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.upconv2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.upconv1(d2), e1], dim=1))\n",
    "        return self.final(d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== è®­ç»ƒå‡†å¤‡ ====\n",
    "model = UNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(POS_WEIGHT).to(DEVICE))\n",
    "\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum((1,2,3))\n",
    "    union = pred.sum((1,2,3)) + target.sum((1,2,3))\n",
    "    return 1 - ((2. * intersection + smooth) / (union + smooth)).mean()\n",
    "\n",
    "def combined_loss(pred, target):\n",
    "    return criterion(pred, target) + dice_loss(pred, target)\n",
    "\n",
    "def compute_iou(pred, target, threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        pred_bin = (torch.sigmoid(pred) > threshold).float()\n",
    "        intersection = (pred_bin * target).sum((2,3))\n",
    "        union = (pred_bin + target).clamp(0,1).sum((2,3))\n",
    "        return (intersection / (union + 1e-8)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== è®­ç»ƒ ====\n",
    "best_iou = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, total_iou = 0, 0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        preds = model(imgs)\n",
    "        loss = combined_loss(preds, masks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_iou += compute_iou(preds, masks)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_iou = total_iou / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | IoU: {avg_iou:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_iou)\n",
    "    if avg_iou > best_iou:\n",
    "        best_iou = avg_iou\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_unet_model.pth\")\n",
    "        print(f\"âœ… ä¿å­˜æ–°æœ€ä½³æ¨¡åž‹ (IoU = {best_iou:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"ðŸ›‘ Early stopping.\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
