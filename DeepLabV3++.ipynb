{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/776lucky/9517_project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "\n",
    "\n",
    "def split_file_lists(rgb_dir, nrg_dir, ratios=(0.64, 0.16, 0.20), seed=42):\n",
    "    \"\"\"\n",
    "    åˆ’åˆ† RGB/NRG æ–‡ä»¶ ID åˆ—è¡¨ä¸º train/val/test ä¸‰éƒ¨åˆ†\n",
    "    ratios: (train_ratio, val_ratio, test_ratio)ï¼Œæ€»å’Œåº”ä¸º1.0\n",
    "    è¿”å›ä¸‰ä¸ªåˆ—è¡¨ï¼Œå…ƒç´ æ ¼å¼ä¸º \"RGB_<id>\"\n",
    "    \"\"\"\n",
    "    # 1. æ‰¾åˆ°æ‰€æœ‰æˆå¯¹çš„å›¾åƒ ID\n",
    "    rgb_ids = [f.replace(\"RGB_\", \"\") for f in os.listdir(rgb_dir) if f.startswith(\"RGB_\")]\n",
    "    nrg_ids = [f.replace(\"NRG_\", \"\") for f in os.listdir(nrg_dir) if f.startswith(\"NRG_\")]\n",
    "    common = sorted(set(rgb_ids) & set(nrg_ids))\n",
    "    # 2. æ‰“ä¹±\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(common)\n",
    "    N = len(common)\n",
    "    n_train = int(ratios[0] * N)\n",
    "    n_val   = int(ratios[1] * N)\n",
    "    # 3. åˆ‡åˆ†\n",
    "    train_ids = common[:n_train]\n",
    "    val_ids   = common[n_train:n_train + n_val]\n",
    "    test_ids  = common[n_train + n_val:]\n",
    "    # 4. æ¢å¤å¸¦å‰ç¼€çš„æ–‡ä»¶å\n",
    "    train_files = [\"RGB_\" + i for i in train_ids]\n",
    "    val_files   = [\"RGB_\" + i for i in val_ids]\n",
    "    test_files  = [\"RGB_\" + i for i in test_ids]\n",
    "    print(f\"âœ… å…± {N} å¼ å›¾ï¼Œåˆ’åˆ†ä¸º train={len(train_files)}, val={len(val_files)}, test={len(test_files)}\")\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "def save_prediction_images(model, dataset, epoch, indices=[0, 1, 2], save_dir=\"predictions\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    for idx in indices:\n",
    "        img, mask = dataset[idx]\n",
    "        with torch.no_grad():\n",
    "            pred = model(img.unsqueeze(0).to(DEVICE))['out']\n",
    "            pred = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
    "\n",
    "        img_rgb = img[:3].permute(1, 2, 0).numpy()\n",
    "        mask_np = mask.squeeze().numpy()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axs[0].imshow(img_rgb); axs[0].set_title(\"RGB Image\")\n",
    "        axs[1].imshow(mask_np, cmap='gray'); axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(pred, cmap='gray'); axs[2].set_title(\"Prediction\")\n",
    "        for ax in axs: ax.axis(\"off\")\n",
    "\n",
    "        save_path = os.path.join(save_dir, f\"epoch_{epoch}_idx_{idx}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"ğŸ“¸ é¢„æµ‹å›¾å·²ä¿å­˜è‡³ {save_path}\")\n",
    "\n",
    "# ===== æ•°æ®é¢„å¤„ç†éƒ¨åˆ† =====\n",
    "def build_file_lists(rgb_dir, nrg_dir, train_ratio=0.8):\n",
    "    rgb_files = [f.replace(\"RGB_\", \"\") for f in os.listdir(rgb_dir) if f.startswith(\"RGB_\")]\n",
    "    nrg_files = [f.replace(\"NRG_\", \"\") for f in os.listdir(nrg_dir) if f.startswith(\"NRG_\")]\n",
    "    common_ids = sorted(set(rgb_files) & set(nrg_files))\n",
    "    print(f\"âœ… æ‰¾åˆ° {len(common_ids)} å¼  RGB å’Œ NRG å¯¹åº”å›¾åƒ\")\n",
    "\n",
    "    rgb_filenames = [\"RGB_\" + fid for fid in common_ids]\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(rgb_filenames)\n",
    "    n_train = int(train_ratio * len(rgb_filenames))\n",
    "    return rgb_filenames[:n_train], rgb_filenames[n_train:]\n",
    "\n",
    "\n",
    "class FourChannelSegmentationDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, nrg_dir, mask_dir, file_list, image_size=(256,256), augment=False):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.nrg_dir = nrg_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.file_list = file_list\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "\n",
    "        # å½’ä¸€åŒ–å‚æ•°ï¼šRGB ç”¨ ImageNetï¼ŒNIR æ²¿ç”¨ R é€šé“\n",
    "        mean = [0.485, 0.456, 0.406, 0.485]\n",
    "        std  = [0.229, 0.224, 0.225, 0.229]\n",
    "\n",
    "        # å›¾åƒå¢å¼ºï¼ˆå«å½’ä¸€åŒ–ï¼‰\n",
    "        base_img_tf = [\n",
    "            T.ToPILImage(), T.Resize(self.image_size),\n",
    "            T.ToTensor(), T.Normalize(mean, std),\n",
    "        ]\n",
    "        aug_img_tf = [\n",
    "            T.ToPILImage(), T.Resize(self.image_size),\n",
    "            T.RandomHorizontalFlip(), T.RandomRotation(15),\n",
    "            T.ToTensor(), T.Normalize(mean, std),\n",
    "        ]\n",
    "        self.img_transform  = T.Compose(aug_img_tf if augment else base_img_tf)\n",
    "\n",
    "        # mask å¢å¼ºï¼ˆä¸å½’ä¸€åŒ–ï¼Œåª flip/rotate â†’ resize â†’ to-tensorï¼‰\n",
    "        base_mask_tf = [\n",
    "            T.ToPILImage(), T.Resize(self.image_size),\n",
    "            T.ToTensor(),\n",
    "        ]\n",
    "        aug_mask_tf  = [\n",
    "            T.ToPILImage(), T.Resize(self.image_size),\n",
    "            T.RandomHorizontalFlip(), T.RandomRotation(15),\n",
    "            T.ToTensor(),\n",
    "        ]\n",
    "        self.mask_transform = T.Compose(aug_mask_tf if augment else base_mask_tf)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file_list[idx]\n",
    "        img_id   = filename.replace(\"RGB_\", \"\")\n",
    "        rgb_path = os.path.join(self.rgb_dir, filename)\n",
    "        nrg_path = os.path.join(self.nrg_dir, \"NRG_\" + img_id)\n",
    "        mask_path= os.path.join(self.mask_dir, \"mask_\" + img_id)\n",
    "\n",
    "        # è¯»å…¥å¹¶æ‹¼é€šé“\n",
    "        rgb = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "        nrg = cv2.imread(nrg_path)\n",
    "        nir = nrg[:, :, 0]\n",
    "        img_4ch = np.concatenate((rgb, nir[..., None]), axis=-1)\n",
    "\n",
    "        # äºŒå€¼åŒ– mask\n",
    "        mask = (cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) > 127).astype(np.float32)\n",
    "\n",
    "        # åŒä¸€ seed ä¿è¯ img/mask éšæœºå‚æ•°ä¸€è‡´\n",
    "        seed = torch.randint(0, 1_000_000, (1,)).item()\n",
    "        torch.manual_seed(seed)\n",
    "        img_tensor  = self.img_transform(img_4ch)\n",
    "        torch.manual_seed(seed)\n",
    "        mask_tensor = self.mask_transform(mask)\n",
    "\n",
    "        return img_tensor, (mask_tensor > 0.5).float()\n",
    "\n",
    "\n",
    "def get_datasets(base_dir=\"9517_project/USA_segmentation\", image_size=(256,256)):\n",
    "    rgb_dir  = os.path.join(base_dir, \"RGB_images\")\n",
    "    nrg_dir  = os.path.join(base_dir, \"NRG_images\")\n",
    "    mask_dir = os.path.join(base_dir, \"masks\")\n",
    "    # ä¸‰ä»½åˆ—è¡¨\n",
    "    train_files, val_files, test_files = split_file_lists(rgb_dir, nrg_dir)\n",
    "    # æ„é€  Dataset\n",
    "    train_ds = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, train_files, image_size, augment=True)\n",
    "    val_ds   = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, val_files,   image_size, augment=False)\n",
    "    test_ds  = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, test_files,  image_size, augment=False)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "\n",
    "# ===== æ¨¡å‹è®­ç»ƒéƒ¨åˆ† =====\n",
    "# === 1. å‚æ•°è®¾ç½® ===\n",
    "IMG_SIZE = (256, 256)\n",
    "IN_CHANNELS = 4\n",
    "OUT_CHANNELS = 1\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === 2. åŠ è½½æ•°æ® ===\n",
    "train_ds, val_ds, test_ds = get_datasets(\"9517_project/USA_segmentation\", image_size=IMG_SIZE)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# === 3. ä¿®æ”¹ DeepLabV3+ æ¨¡å‹ä»¥æ¥å— 4 é€šé“è¾“å…¥ ===\n",
    "class ModifiedDeepLabV3(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1):\n",
    "        super().__init__()\n",
    "        # åŠ è½½é¢„è®­ç»ƒçš„ DeepLabV3+ æ¨¡å‹\n",
    "        self.deeplab = deeplabv3_resnet101(weights=DeepLabV3_ResNet101_Weights.DEFAULT)\n",
    "\n",
    "        # ä¿®æ”¹è¾“å…¥å±‚ä»¥æ¥å— 4 é€šé“\n",
    "        original_conv1 = self.deeplab.backbone.conv1\n",
    "        self.deeplab.backbone.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            original_conv1.out_channels,\n",
    "            kernel_size=original_conv1.kernel_size,\n",
    "            stride=original_conv1.stride,\n",
    "            padding=original_conv1.padding,\n",
    "            bias=original_conv1.bias\n",
    "        )\n",
    "\n",
    "        # å°†é¢„è®­ç»ƒæƒé‡å¤åˆ¶åˆ°æ–°å·ç§¯å±‚çš„ RGB é€šé“ï¼Œå¹¶éšæœºåˆå§‹åŒ– NIR é€šé“\n",
    "        with torch.no_grad():\n",
    "            self.deeplab.backbone.conv1.weight[:, :3] = original_conv1.weight\n",
    "            self.deeplab.backbone.conv1.weight[:, 3:] = original_conv1.weight[:, :1]\n",
    "\n",
    "        # ä¿®æ”¹åˆ†ç±»å™¨ä»¥æ¥å— ASPP è¾“å‡ºçš„ 2048 é€šé“\n",
    "        self.deeplab.classifier = nn.Sequential(\n",
    "            nn.Conv2d(2048, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(256, out_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        # åˆå§‹åŒ–æœ€ç»ˆå·ç§¯å±‚çš„åç½®\n",
    "        nn.init.constant_(self.deeplab.classifier[-1].bias, -2.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deeplab(x)\n",
    "\n",
    "# === 4. åˆå§‹åŒ–æ¨¡å‹ ===\n",
    "model = ModifiedDeepLabV3(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# === 5. æŸå¤±å‡½æ•°ä¸ IoU ===\n",
    "def focal_loss(pred, target, alpha=0.75, gamma=2):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
    "    prob = torch.sigmoid(pred)\n",
    "    loss = alpha * (1 - prob)**gamma * bce\n",
    "    return loss.mean()\n",
    "\n",
    "def tversky_loss(pred, target, alpha=0.7, beta=0.3, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    TP = (pred * target).sum((1,2,3))\n",
    "    FP = ((1 - target) * pred).sum((1,2,3))\n",
    "    FN = (target * (1 - pred)).sum((1,2,3))\n",
    "    return 1 - ((TP + smooth) / (TP + alpha * FP + beta * FN + smooth)).mean()\n",
    "\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum((1,2,3))\n",
    "    union = pred.sum((1,2,3)) + target.sum((1,2,3))\n",
    "    return 1 - ((2. * intersection + smooth) / (union + smooth)).mean()\n",
    "\n",
    "def combined_loss(pred, target):\n",
    "    return 0.3 * focal_loss(pred, target, alpha=0.85, gamma=1.5) + 0.7 * tversky_loss(pred, target)\n",
    "\n",
    "def compute_iou(pred, target, threshold=0.1):\n",
    "    with torch.no_grad():\n",
    "        pred_bin = (torch.sigmoid(pred) > threshold).float()\n",
    "        intersection = (pred_bin * target).sum((2, 3))\n",
    "        union = (pred_bin + target).clamp(0, 1).sum((2, 3))\n",
    "        return (intersection / (union + 1e-8)).mean().item()\n",
    "\n",
    "def visualize_prediction(model, dataset, index=0):\n",
    "    model.eval()\n",
    "    img, mask = dataset[index]\n",
    "    with torch.no_grad():\n",
    "        pred = model(img.unsqueeze(0).to(DEVICE))['out']\n",
    "        pred = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
    "\n",
    "    img_rgb = img[:3].permute(1, 2, 0).numpy()\n",
    "    mask_np = mask.squeeze().numpy()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(img_rgb); plt.title(\"RGB Image\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(mask_np, cmap='gray'); plt.title(\"Ground Truth\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(pred, cmap='gray'); plt.title(\"Prediction\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# === 6. æ¨¡å‹è®­ç»ƒä¸»å¾ªç¯ï¼ˆæ”¹ï¼‰ ===\n",
    "best_val_iou = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# æ‹¿ç¬¬ 2 æ¡æ ·æœ¬è¯•è¯•çœ‹\n",
    "img, mask = train_ds[6]   # img: [4,H,W], mask: [1,H,W]\n",
    "# åå½’ä¸€åŒ–å¹¶æå–å‰ä¸‰é€šé“\n",
    "mean = torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "std  = torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "rgb = img[:3] * std + mean  # åå½’ä¸€åŒ–\n",
    "rgb = rgb.permute(1,2,0).numpy()\n",
    "\n",
    "m = mask.squeeze().numpy()\n",
    "print(train_ds.file_list[2])      # ä¾‹å¦‚ï¼š'RGB_000123.png'\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(rgb); plt.title(\"RGB\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(rgb); \n",
    "plt.imshow(m, cmap=\"jet\", alpha=0.5); \n",
    "plt.title(\"Overlay Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "imgs, masks = next(iter(train_loader))\n",
    "print(\"img min/max:\", imgs.min().item(), imgs.max().item())\n",
    "print(\"mask min/max:\", masks.min().item(), masks.max().item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ DeepLabV3+ï¼ˆå«éªŒè¯é›†è¯„ä¼°ï¼‰\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- 1) è®­ç»ƒ ---\n",
    "    model.train()\n",
    "    train_loss, train_iou = 0.0, 0.0\n",
    "    t0 = time.time()\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        preds = model(imgs)['out']\n",
    "        loss = combined_loss(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_iou  += compute_iou(preds, masks)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_iou  /= len(train_loader)\n",
    "\n",
    "    # --- 2) éªŒè¯ ---\n",
    "    model.eval()\n",
    "    val_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "            preds = model(imgs)['out']\n",
    "            val_iou += compute_iou(preds, masks)\n",
    "    val_iou /= len(val_loader)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"âœ… Epoch {epoch}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f} | \"\n",
    "          f\" Val IoU: {val_iou:.4f} | Time: {elapsed:.1f}s\")\n",
    "\n",
    "    # --- 3) è°ƒåº¦ & EarlyStopï¼ˆç”¨ val_iouï¼‰ ---\n",
    "    scheduler.step(val_iou)\n",
    "\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_deeplabv3plus_model.pth\")\n",
    "        print(f\"ğŸ‰ éªŒè¯é›† IoU æå‡åˆ° {best_val_iou:.4f}ï¼Œæ¨¡å‹å·²ä¿å­˜\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"ğŸ•’ éªŒè¯é›† IoU æœªæå‡ï¼ˆ{patience_counter}/{PATIENCE}ï¼‰\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"ğŸ›‘ Early stopping è§¦å‘ï¼Œæœ€ä½³ Val IoU = {best_val_iou:.4f}\")\n",
    "            break\n",
    "\n",
    "    # --- 4) ï¼ˆå¯é€‰ï¼‰å®šæœŸå¯è§†åŒ–éªŒè¯é›†ä¸Šçš„æ•ˆæœ ---\n",
    "    if epoch % 5 == 0:\n",
    "        save_prediction_images(model, val_ds, epoch, indices=[0,1,2], save_dir=\"predictions/val\")\n",
    "        visualize_prediction(model, val_ds, index=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
