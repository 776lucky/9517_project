{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# === 1. æž„é€ å¯é…å¯¹çš„å›¾åƒåˆ—è¡¨ ===\n",
    "def build_file_lists(rgb_dir, nrg_dir, train_ratio=0.8):\n",
    "    rgb_files = [f.replace(\"RGB_\", \"\") for f in os.listdir(rgb_dir) if f.startswith(\"RGB_\")]\n",
    "    nrg_files = [f.replace(\"NRG_\", \"\") for f in os.listdir(nrg_dir) if f.startswith(\"NRG_\")]\n",
    "    common_ids = sorted(set(rgb_files) & set(nrg_files))\n",
    "    print(f\"âœ… æ‰¾åˆ° {len(common_ids)} å¼  RGB å’Œ NRG å¯¹åº”å›¾åƒ\")\n",
    "\n",
    "    rgb_filenames = [\"RGB_\" + fid for fid in common_ids]\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(rgb_filenames)\n",
    "    n_train = int(train_ratio * len(rgb_filenames))\n",
    "    return rgb_filenames[:n_train], rgb_filenames[n_train:]\n",
    "\n",
    "# === 2. Dataset å®šä¹‰ ===\n",
    "class FourChannelSegmentationDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, nrg_dir, mask_dir, file_list, image_size=(256, 256)):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.nrg_dir = nrg_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.file_list = file_list\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.transform_img = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize(self.image_size),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file_list[idx]\n",
    "        img_id = filename.replace(\"RGB_\", \"\")\n",
    "        rgb_path = os.path.join(self.rgb_dir, filename)\n",
    "        nrg_path = os.path.join(self.nrg_dir, \"NRG_\" + img_id)\n",
    "        mask_path = os.path.join(self.mask_dir, \"mask_\" + img_id)\n",
    "\n",
    "        rgb = cv2.imread(rgb_path)\n",
    "        nrg = cv2.imread(nrg_path)\n",
    "        nir = nrg[:, :, 0][:, :, np.newaxis]\n",
    "\n",
    "        img_4ch = np.concatenate((rgb, nir), axis=-1)\n",
    "        rgb_tensor = self.transform_img(img_4ch[:, :, :3])\n",
    "        nir_tensor = self.transform_img(nir.squeeze(-1))\n",
    "        img_tensor = torch.cat([rgb_tensor, nir_tensor], dim=0)  # shape: (4, H, W)\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, self.image_size)\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "        return img_tensor, mask_tensor\n",
    "\n",
    "def build_file_lists(rgb_dir, nrg_dir, train_ratio=0.8):\n",
    "    rgb_files = [f.replace(\"RGB_\", \"\") for f in os.listdir(rgb_dir) if f.startswith(\"RGB_\")]\n",
    "    nrg_files = [f.replace(\"NRG_\", \"\") for f in os.listdir(nrg_dir) if f.startswith(\"NRG_\")]\n",
    "    common_ids = sorted(set(rgb_files) & set(nrg_files))\n",
    "    rgb_filenames = [\"RGB_\" + fid for fid in common_ids]\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(rgb_filenames)\n",
    "    n_train = int(train_ratio * len(rgb_filenames))\n",
    "    return rgb_filenames[:n_train], rgb_filenames[n_train:]\n",
    "\n",
    "def get_datasets(base_dir=\"USA_segmentation\", image_size=(256, 256)):\n",
    "    rgb_dir = os.path.join(base_dir, \"RGB_images\")\n",
    "    nrg_dir = os.path.join(base_dir, \"NRG_images\")\n",
    "    mask_dir = os.path.join(base_dir, \"masks\")\n",
    "    train_files, test_files = build_file_lists(rgb_dir, nrg_dir)\n",
    "    train_dataset = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, train_files, image_size)\n",
    "    test_dataset = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, test_files, image_size)\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å›¾åƒ shape: torch.Size([4, 256, 256])\n",
      "âœ… æŽ©ç  shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 3. ä½¿ç”¨ç¤ºä¾‹ ===\n",
    "rgb_dir = \"USA_segmentation/RGB_images\"\n",
    "nrg_dir = \"USA_segmentation/NRG_images\"\n",
    "mask_dir = \"USA_segmentation/masks\"\n",
    "\n",
    "train_files, test_files = build_file_lists(rgb_dir, nrg_dir)\n",
    "\n",
    "train_dataset = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, train_files)\n",
    "test_dataset = FourChannelSegmentationDataset(rgb_dir, nrg_dir, mask_dir, test_files)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# === 4. éªŒè¯æ˜¯å¦ä¸º 4 é€šé“å›¾åƒ ===\n",
    "sample_img, sample_mask = train_dataset[0]\n",
    "print(\"âœ… å›¾åƒ shape:\", sample_img.shape)      # åº”ä¸º (4, 256, 256)\n",
    "print(\"âœ… æŽ©ç  shape:\", sample_mask.shape)    # åº”ä¸º (1, 256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m best_iou = \u001b[32m0\u001b[39m\n\u001b[32m      3\u001b[39m patience_counter = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mEPOCHS\u001b[49m):\n\u001b[32m      6\u001b[39m     model.train()\n\u001b[32m      7\u001b[39m     total_loss, total_iou = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "# ==== å¯åŠ¨è®­ç»ƒ ====\n",
    "best_iou = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, total_iou = 0, 0\n",
    "\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        preds = model(imgs)\n",
    "        loss = combined_loss(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_iou += compute_iou(preds, masks)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_iou = total_iou / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | IoU: {avg_iou:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_iou)\n",
    "    if avg_iou > best_iou:\n",
    "        best_iou = avg_iou\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_unet_model.pth\")\n",
    "        print(f\"âœ… ä¿å­˜æ–°æœ€ä½³æ¨¡åž‹ (IoU = {best_iou:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"ðŸ›‘ Early stopping.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
